# Overview

**Objective**: Create a Reinforcement Learning algorithm to learn to play and complete the track


# Files

Descriptions added as headers for each file

### TODO: Coursework Tasks

* **5%** - Define a Domain and the task - Write Up
* **5%** - Define a State Transition Function - Write Up
* **5%** - Define a Reward Function - Write Up
* **5%** - Choose a Policy - Write Up
* **5%** - Represent the Problem as a Graph - Write Up
* **5%** - Set the original R-Matrix - Code
* **5%** - Set the parameter values for Q-Learning - Code
* **10%** - Set the original Q-matrix and show how it is updated in a learning episode - Code - Implemented
* **10%** - Represent performance vs episodes - Code

* **5%** - Case 2: for repeating the experiment in Case 1 with different gamma values - Code - Partially Implemented
* **5%** - Case 3: for repeating the experiment in Case 1 with different learning rates - Code - Implemented
* **5%** - Case 4: for repeating the experiment in Case 1 with different policies - Code - Need to Confirm What this means
* **5%** - Case 5: for repeating the experiment in Case 1 with different state and reward functions - Code - Implemented

* **5%** - for the scope of the problem - Write Up - Increase Complexities [Fuel, Gravity, nb Actions]
* **20%** - for analysis of results and comparing performance in Case 1, Case 2, Case 3 and Case 4 (5% each) - Code + Write-Up


### TODO: Implement these

* Reward Function
* Initialize R-Matrix

* For analysis:
    * Average Reward
    * Q-Matrix
    * Paths
    * Final Location

* Set epsilon to 0 and run on a different track
    * Observe results
