## References:

1.   Sutton, R.S., Barto, A.G.: Reinforcement  Learning: An Introduction. MIT Press, Cambridge, MA (1998)

2.  Watkins, C.: Learning from Delayed Rewards. Ph.D. thesis, University of Cambridge, Cambridge, England (1989)

3.  Thrun, S.B.: an Efficient Exploration in Reinforcement Learning. Technical Report CMU-CS-92-102, Carnegie Mellon University, Pittsburgh, PA, USA (1992)

4.  Brafman, R.I., Tennenholtz, M.: R-MAX - a general polynomial time algorithm for near-optimal Reinforcement learning. Journal of Machine Learning Research 3 (2002) 213–231

5.  Ishii, S., Yoshida, W., Yoshimoto, J.: Control of exploitation-exploration meta parameter in Reinforcement learning. Neural Networks 15(4-6) (2002) 665–687

6.  Heidrich-Meisner, V.: Interview with Richard S. Sutton. K¨unstliche Intelligenz 3 (2009) 41–43

7.  Vermorel, J., Mohri, M.: Multi-armed bandit algorithms and empirical evaluation. In: Proceedings of the 16th European Conference on Machine Learning (ECML’05), Porto, Portugal (2005) 437–448

8.  Caelen, O., Bontempi, G.: Improving the exploration strategy in bandit algorithms. In: Learning and Intelligent Optimization. Number 5313 in LNCS. Springer (2008) 56–68

9.  Rummery, G.A., Niranjan, M.: On-line Q-learning using connectionist systems. Technical Report CUED/F-
INFENG/TR 166, Cambridge University (1994)

10. Bertsekas, D.P.: Dynamic Programming: Deterministic and Stochastic Models. Prentice Hall (1987)

11. George, A.P., Powell, W.B.: Adaptive step sizes for recursive estimation with applications in approximate dynamic programming. Machine Learning 65(1) (2006) 167–198

12. Robbins, H.: Some aspects of the sequential design of experiments. Bulletin of the American Mathematical Society 58 (1952) 527–535

13. Awerbuch, B., Kleinberg, R.D.: Adaptive routing with end-to-end feedback: Distributed learning and geometric approaches. In: Proceedings of the 36th Annual ACM Symposium on Theory of Computing, Chicago, IL, USA, ACM (2004) 45–53

14. Azoulay-Schwartz, R., Kraus, S., Wilkenfeld, J.: Exploitation vs. exploration: Choosing a supplier in an environment of incomplete information. Decision Support Systems 38(1) (2004) 1–18

15. Mnih, Volodymyr, Koray Kavukcuoglu, David Silver, Andrei A. Rusu, Joel Veness, Marc G. Bellemare, Alex Graves, et al. ‘Human-Level Control through Deep Reinforcement  Learning’. Nature 518, no. 7540 (25 February 2015): 529–33. doi:10.1038/nature14236

16. Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., Riedmiller, M., 2013. Playing Atari with Deep Reinforcement  Learning. arXiv preprint arXiv:1312.5602.
